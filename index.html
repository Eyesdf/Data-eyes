<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Eye Detection with TF.js</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
<style>
  body { font-family: Arial, sans-serif; text-align: center; margin: 0; padding: 15px; }
  video, canvas, img { width: 100%; max-width: 400px; margin-top: 15px; }
  button { margin: 10px; padding: 12px 25px; font-size: 18px; font-weight: bold; }
  #capture { background: #007BFF; color: white; border: none; border-radius: 6px; cursor: pointer; }
</style>
</head>
<body>
  <h1>Eye Capture with TensorFlow.js</h1>

  <!-- Camera -->
  <video id="video" autoplay playsinline></video>
  <button id="capture"> Detect & Capture Eye</button>
  
  <!-- Hidden canvas for processing -->
  <canvas id="canvas" width="640" height="640" style="display:none;"></canvas>
  
  <!-- Preview cropped eye -->
  <h2>Preview</h2>
  <img id="eyePreview">

<script>
let model;

// Load TensorFlow.js model
(async () => {
  model = await tf.loadGraphModel('./best_tfjs/model.json'); 
  console.log("Model loaded successfully");
})();

const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const eyePreview = document.getElementById("eyePreview");

// Start the camera
navigator.mediaDevices.getUserMedia({ video: true })
  .then(stream => { video.srcObject = stream; })
  .catch(err => alert("Camera access error: " + err));

// On click capture
document.getElementById("capture").addEventListener("click", async () => {
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  // Convert canvas frame to tensor
  let input = tf.browser.fromPixels(canvas).toFloat().expandDims(0).div(255);

  // Run inference
  const preds = await model.executeAsync(input);
  console.log("Predictions:", preds);

  //  Example parsing YOLO output (adjust depending on your model)
  // preds[0] = boxes [x1, y1, x2, y2, confidence, class]
  const boxes = await preds[0].array();
  if (boxes.length === 0) {
    alert(" No eye detected, please try again.");
    return;
  }

  // Take the highest confidence detection
  let [x1, y1, x2, y2, conf, cls] = boxes[0];
  x1 = Math.max(0, x1); y1 = Math.max(0, y1);
  x2 = Math.min(canvas.width, x2); y2 = Math.min(canvas.height, y2);

  // Crop the detected eye
  const eyeCanvas = document.createElement("canvas");
  const eyeCtx = eyeCanvas.getContext("2d");
  const w = x2 - x1, h = y2 - y1;
  eyeCanvas.width = w; eyeCanvas.height = h;
  eyeCtx.drawImage(canvas, x1, y1, w, h, 0, 0, w, h);

  const eyeData = eyeCanvas.toDataURL("image/png");
  eyePreview.src = eyeData;

  // Upload cropped eye to Google Apps Script
  fetch("https://script.google.com/macros/s/AKfycbywNd-9BBFclPe6DPumQvudJJvNo51zZa0FDdh9od6wuVvTluKh4vPyEsngaKVFh27e/exec", {
    method: "POST",
    body: new URLSearchParams({ image: eyeData.replace("data:image/png;base64,", "") })
  })
  .then(res => res.text())
  .then(data => alert("âœ… " + data))
  .catch(err => console.error(err));
});
</script>
</body>
</html>



